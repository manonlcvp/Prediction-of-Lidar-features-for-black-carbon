{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94d8f33",
   "metadata": {},
   "source": [
    "# Prédiction des données lidar avec les données physiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d84f5a",
   "metadata": {},
   "source": [
    "#### Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb53712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_absolute_error, max_error, mean_absolute_percentage_error\n",
    "\n",
    "import math\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f797e4b",
   "metadata": {},
   "source": [
    "#### Données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17aa9f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fractal_dimension', 'fraction_of_coating (%)',\n",
       "       'primary_particle_size (nm)', 'number_of_primary_particles',\n",
       "       'vol_equi_radius_outer (nm)', 'vol_equi_radius_inner (nm)',\n",
       "       'equi_mobility_dia (nm)', 'mie_epsilon', 'length_scale_factor',\n",
       "       'm_real_bc', 'm_im_bc', 'm_real_organics', 'm_im_organics',\n",
       "       'volume_total (nm^3)', 'volume_bc (nm^3)', 'volume_organics (nm^3)',\n",
       "       'density_bc (g/cm^3)', 'density_organics (g/cm^3)', 'mass_bc (g)',\n",
       "       'mass_organics (g)', 'mass_total  (g)', 'mr_total/bc', 'mr_nonBC/BC',\n",
       "       'MEC_530', 'MEC_467', 'Cbac_530', 'Cbac_467', 'MBC_530', 'MBC_467',\n",
       "       'LR_530', 'LR_467', 'CR', 'BAE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('./df_cleaned.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94a8870b-6796-4af6-b55c-1be1f09c436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :23]  # données particules\n",
    "Y = df.iloc[:,23:31]  # données optiques\n",
    "L = df.iloc[:,31:]  # données Lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd2acc2-d278-486e-aef8-99780a24e1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fractal_dimension', 'fraction_of_coating (%)',\n",
      "       'primary_particle_size (nm)', 'number_of_primary_particles',\n",
      "       'vol_equi_radius_outer (nm)', 'vol_equi_radius_inner (nm)',\n",
      "       'equi_mobility_dia (nm)', 'mie_epsilon', 'length_scale_factor',\n",
      "       'm_real_bc', 'm_im_bc', 'm_real_organics', 'm_im_organics',\n",
      "       'volume_total (nm^3)', 'volume_bc (nm^3)', 'volume_organics (nm^3)',\n",
      "       'density_bc (g/cm^3)', 'density_organics (g/cm^3)', 'mass_bc (g)',\n",
      "       'mass_organics (g)', 'mass_total  (g)', 'mr_total/bc', 'mr_nonBC/BC'],\n",
      "      dtype='object')\n",
      "Index(['MEC_530', 'MEC_467', 'Cbac_530', 'Cbac_467', 'MBC_530', 'MBC_467',\n",
      "       'LR_530', 'LR_467'],\n",
      "      dtype='object')\n",
      "Index(['CR', 'BAE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n",
    "print(Y.columns)\n",
    "print(L.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd914de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9fdedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, L,\n",
    "            test_size=0.30,\n",
    "            random_state=10)\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "X_test=X_test.reset_index(drop=True)\n",
    "Y_test=Y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train_transformed = scaler.fit_transform(X_train)  #pt.fit_transform(X_train)\n",
    "X_test_transformed =  scaler.fit_transform(X_test)   #pt.transform(X_test)\n",
    "\n",
    "Y_train_transformed = pd.DataFrame(pt.fit_transform(Y_train), columns=Y_train.columns)\n",
    "Y_test_transformed = pd.DataFrame(pt.transform(Y_test), columns=Y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39e26783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fractal_dimension', 'fraction_of_coating (%)',\n",
      "       'primary_particle_size (nm)', 'number_of_primary_particles',\n",
      "       'vol_equi_radius_outer (nm)', 'vol_equi_radius_inner (nm)',\n",
      "       'equi_mobility_dia (nm)', 'mie_epsilon', 'length_scale_factor',\n",
      "       'm_real_bc', 'm_im_bc', 'm_real_organics', 'm_im_organics',\n",
      "       'volume_total (nm^3)', 'volume_bc (nm^3)', 'volume_organics (nm^3)',\n",
      "       'density_bc (g/cm^3)', 'density_organics (g/cm^3)', 'mass_bc (g)',\n",
      "       'mass_organics (g)', 'mass_total  (g)', 'mr_total/bc', 'mr_nonBC/BC'],\n",
      "      dtype='object')\n",
      "Index(['CR', 'BAE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "para  = X.columns\n",
    "print(para)\n",
    "print(Y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d74a36",
   "metadata": {},
   "source": [
    "Nombre de lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e899a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3883"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4cbada-b003-49e8-81fb-a09b351f04f9",
   "metadata": {},
   "source": [
    "## Régression linéaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5286fe-dffa-4ed1-8098-4ab200b98a6e",
   "metadata": {},
   "source": [
    "### Définition\n",
    "La régression linéaire est une méthode statistique et machine learning utilisée pour modéliser la relation entre une **variable cible** (\\(Y\\)) et une ou plusieurs **variables explicatives** (\\(X\\)) à l'aide d'une fonction linéaire.\n",
    "\n",
    "---\n",
    "\n",
    "### Modèle mathématique\n",
    "Le modèle de régression linéaire est défini par :\n",
    "\n",
    "$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon $\n",
    "- $Y$ : Variable cible (dépendante).\n",
    "- $X_1, X_2, \\dots, X_p$ : Variables explicatives (indépendantes).\n",
    "- $\\beta_0$ : Intercept (ordonnée à l'origine).\n",
    "- $\\beta_1, \\beta_2, \\dots, \\beta_p$ : Coefficients des variables.\n",
    "- $\\epsilon$ : Terme d'erreur (résiduel).\n",
    "\n",
    "---\n",
    "\n",
    "### Objectif\n",
    "- Trouver les coefficients $\\beta_0, \\beta_1, \\dots, \\beta_p$ qui minimisent l'erreur entre les prédictions du modèle $\\hat{Y}$ et les valeurs réelles $Y$.\n",
    "- Cette minimisation est généralement réalisée par la **méthode des moindres carrés**, qui minimise la somme des carrés des résidus :\n",
    "$ \\text{Erreur} = \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94dee018-eaa2-45f5-b272-eee738391389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle pour la variable 'CR' enregistré sous Best_models/X_L/Linear\\CR_best_model_linear.joblib\n",
      "Target Column 'CR'\n",
      "MSE: 220651076206.2078, MAPE: 492488.4962253989, R²: -11696358993438.053\n",
      "----------------------------------------\n",
      "Modèle pour la variable 'BAE' enregistré sous Best_models/X_L/Linear\\BAE_best_model_linear.joblib\n",
      "Target Column 'BAE'\n",
      "MSE: 202523403570.62344, MAPE: 128366.3746839029, R²: -25175063667.090736\n",
      "----------------------------------------\n",
      "  Target Column           MSE           MAPE            R2\n",
      "0            CR  2.206511e+11  492488.496225 -1.169636e+13\n",
      "1           BAE  2.025234e+11  128366.374684 -2.517506e+10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import pandas as pd\n",
    "from joblib import dump  # Importation de joblib pour sauvegarder les modèles\n",
    "\n",
    "# Initialiser le modèle de régression linéaire\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les métriques et les prédictions\n",
    "results_linear = []\n",
    "Y_pred_linear = pd.DataFrame()\n",
    "\n",
    "# Créer le dossier pour les modèles si il n'existe pas\n",
    "output_dir = 'Best_models/X_L/Linear'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Boucle sur chaque variable cible\n",
    "for i, col in enumerate(Y_train.columns):\n",
    "    # Ajuster le modèle sur la colonne actuelle (transformée)\n",
    "    linear_model.fit(X_train_transformed[:k, :], Y_train_transformed.iloc[:k, i])\n",
    "    \n",
    "    # Prédire les valeurs sur le jeu de test (transformé)\n",
    "    y_pred = linear_model.predict(X_test_transformed[:k, :])\n",
    "    y_true = Y_test.iloc[:k, i]\n",
    "    \n",
    "    # Pas de transformation inverse ici : on utilise directement y_pred (transformation appliquée)\n",
    "    y_pred_original = y_pred  # Les prédictions sont déjà dans l'échelle transformée\n",
    "\n",
    "    # Calculer les métriques\n",
    "    mse = mean_squared_error(y_true, y_pred_original)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred_original)\n",
    "    r2 = r2_score(y_true, y_pred_original)\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    results_linear.append({\n",
    "        'Target Column': col,\n",
    "        'MSE': mse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    })\n",
    "    \n",
    "    # Stocker les prédictions dans un DataFrame\n",
    "    Y_pred_linear[col] = y_pred_original\n",
    "\n",
    "    # Définir le chemin d'enregistrement du modèle pour chaque colonne\n",
    "    model_path = os.path.join(output_dir, f'{col}_best_model_linear.joblib')  # Sauvegarder dans le bon dossier\n",
    "    dump(linear_model, model_path)\n",
    "    print(f\"Modèle pour la variable '{col}' enregistré sous {model_path}\")\n",
    "\n",
    "    # Afficher les métriques pour la variable cible\n",
    "    print(f\"Target Column '{col}'\")\n",
    "    print(f\"MSE: {mse}, MAPE: {mape}, R²: {r2}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Créer un DataFrame pour résumer les résultats\n",
    "params_linear = pd.DataFrame(results_linear)\n",
    "\n",
    "# Afficher le tableau des résultats\n",
    "print(params_linear)\n",
    "\n",
    "# Afficher les prédictions (si nécessaire)\n",
    "# print(Y_pred_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce25db",
   "metadata": {},
   "source": [
    "## Random split (KRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cce994-2909-4d1b-b641-39c02fb0de5a",
   "metadata": {},
   "source": [
    "### Définition\n",
    "La **régression à noyau** (KRR) combine deux concepts puissants :\n",
    "1. **Régression ridge** : Une variante de la régression linéaire qui ajoute une pénalité pour limiter la complexité du modèle.\n",
    "2. **Trick du noyau** : Une technique permettant de modéliser des relations non linéaires en projetant les données dans un espace de caractéristiques de dimension supérieure.\n",
    "\n",
    "---\n",
    "\n",
    "### Modèle mathématique\n",
    "La KRR minimise la fonction coût suivante :\n",
    "\n",
    "$ \\text{Erreur} = ||Y - K \\alpha||^2 + \\lambda ||\\alpha||^2 $\n",
    "- $Y$ : Cibles réelles.\n",
    "- $K$ : Matrice de noyau, définie par $K_{ij} = k(X_i, X_j)$, où $k(\\cdot, \\cdot)$ est une fonction de noyau.\n",
    "- $\\alpha$ : Coefficients à déterminer.\n",
    "- $\\lambda$ : Hyperparamètre de régularisation qui contrôle le compromis biais/variance.\n",
    "\n",
    "---\n",
    "\n",
    "### Fonction de noyau\n",
    "La fonction de noyau $k(X_i, X_j)$ mesure la similarité entre deux observations. Les noyaux courants sont :\n",
    "- **Linéaire** : $k(X_i, X_j) = X_i^T X_j$\n",
    "- **RBF (Radial Basis Function)** : $k(X_i, X_j) = \\exp\\left(-\\frac{||X_i - X_j||^2}{2\\sigma^2}\\right)$\n",
    "\n",
    "Le choix du noyau permet de capturer des relations linéaires ou non linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d04afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle pour la variable 'CR' enregistré sous Best_models/X_L/KRR\\CR_best_model_KRR.joblib\n",
      "Target Column 'CR'\n",
      "Best Parameters: {'alpha': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "MSE: 0.007280196439357656, MAPE: 0.10234298566648692, R²: 0.6140884850345986\n",
      "----------------------------------------\n",
      "Modèle pour la variable 'BAE' enregistré sous Best_models/X_L/KRR\\BAE_best_model_KRR.joblib\n",
      "Target Column 'BAE'\n",
      "Best Parameters: {'alpha': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "MSE: 2.173436776075444, MAPE: 0.44331952066411257, R²: 0.7298267348287547\n",
      "----------------------------------------\n",
      "  Target Column  alpha kernel  gamma       MSE      MAPE        R2\n",
      "0            CR    0.1    rbf      1  0.007280  0.102343  0.614088\n",
      "1           BAE    0.1    rbf      1  2.173437  0.443320  0.729827\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from joblib import dump  # Importation de joblib pour sauvegarder les modèles\n",
    "\n",
    "# Paramètres pour GridSearchCV pour Kernel Ridge Regression\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10],           # Paramètre de régularisation\n",
    "    'kernel': ['linear', 'rbf'],     # Choix de noyaux\n",
    "    'gamma': [0.1, 1, 10]            # Paramètre pour le noyau 'rbf'\n",
    "}\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible\n",
    "best_models = {}\n",
    "best_params_list = []\n",
    "\n",
    "# Créer le dossier pour les modèles si il n'existe pas\n",
    "output_dir = 'Best_models/X_L/KRR'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Boucle sur chaque variable cible (chaque colonne de Y_train)\n",
    "for i, col in enumerate(Y_train.columns):\n",
    "    # Initialiser un modèle Kernel Ridge\n",
    "    krr = KernelRidge()\n",
    "\n",
    "    # Configurer la recherche de grille\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=krr,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_percentage_error',  # Utiliser MAPE pour optimiser\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Ajuster le modèle sur la colonne actuelle de Y_train\n",
    "    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])\n",
    "\n",
    "    # Obtenir le meilleur modèle\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[col] = best_model\n",
    "\n",
    "    # Prédire sur les données de test\n",
    "    y_pred = best_model.predict(X_test_transformed[:k, :])\n",
    "    y_true = Y_test.iloc[:k, i]\n",
    "\n",
    "    # Calculer les erreurs\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Stocker les résultats\n",
    "    best_params_list.append({\n",
    "        'Target Column': col,\n",
    "        'alpha': grid_search.best_params_['alpha'],\n",
    "        'kernel': grid_search.best_params_['kernel'],\n",
    "        'gamma': grid_search.best_params_['gamma'],\n",
    "        'MSE': mse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié\n",
    "    model_path = os.path.join(output_dir, f'{col}_best_model_KRR.joblib')  # Sauvegarder dans le bon dossier\n",
    "    dump(best_model, model_path)\n",
    "    print(f\"Modèle pour la variable '{col}' enregistré sous {model_path}\")\n",
    "\n",
    "    # Afficher les résultats pour chaque colonne\n",
    "    print(f\"Target Column '{col}'\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(f\"MSE: {mse}, MAPE: {mape}, R²: {r2}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Créer un DataFrame pour résumer les résultats\n",
    "params_KRR = pd.DataFrame(best_params_list)\n",
    "\n",
    "# Afficher le tableau des résultats\n",
    "print(params_KRR)\n",
    "\n",
    "# Créer un DataFrame pour les prédictions\n",
    "Y_pred_KRR = pd.DataFrame()\n",
    "for column, model in best_models.items():\n",
    "    Y_pred_KRR[column] = model.predict(X_test_transformed[:k, :])\n",
    "\n",
    "# Afficher les prédictions\n",
    "#print(Y_pred_KRR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1e526",
   "metadata": {},
   "source": [
    "## Gradient boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81744cb-adb9-4e81-be3e-e37332eaf26c",
   "metadata": {},
   "source": [
    "### Définition\n",
    "Le **Gradient Boosting** est une technique d'ensemble qui construit un modèle puissant en combinant plusieurs modèles faibles (souvent des arbres de décision) de manière séquentielle. À chaque étape, le modèle suivant corrige les erreurs du modèle précédent en optimisant une fonction de perte grâce à la descente de gradient.\n",
    "\n",
    "---\n",
    "\n",
    "### Modèle mathématique\n",
    "L'objectif est de minimiser une fonction de perte $L(Y, \\hat{Y})$, où :\n",
    "- $Y$ : Cibles réelles.\n",
    "- $\\hat{Y}$ : Prédictions du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparamètres clés\n",
    "- **Nombre d'estimateurs** $(n\\_estimators)$ : Nombre total d'arbres.\n",
    "- **Taux d'apprentissage** $(learning\\_rate)$ : Contrôle la contribution de chaque arbre.\n",
    "- **Profondeur maximale** $(max\\_depth)$ : Limite la complexité des arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d02f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle pour la variable 'CR' enregistré sous Best_models/X_L/GB\\CR_best_model_GBR.joblib\n",
      "Variable de sortie 'CR'\n",
      "Meilleurs paramètres : {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 300}\n",
      "Meilleur score (MAPE négatif) : -0.04168073607851962\n",
      "MSE: 0.010432305222432388, MAPE: 0.20795463195796818, R²: 0.4470002634536647\n",
      "----------------------------------------\n",
      "Modèle pour la variable 'BAE' enregistré sous Best_models/X_L/GB\\BAE_best_model_GBR.joblib\n",
      "Variable de sortie 'BAE'\n",
      "Meilleurs paramètres : {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "Meilleur score (MAPE négatif) : -0.13382454959911722\n",
      "MSE: 5.438318139802836, MAPE: 0.5764805803787817, R²: 0.32397933768120646\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from joblib import dump  # Importation de joblib pour sauvegarder les modèles\n",
    "\n",
    "# Paramètres pour GridSearchCV pour GradientBoostingRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 300, 500],\n",
    "    'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_depth': [2, 3]\n",
    "}\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible\n",
    "best_models = {}\n",
    "best_params_list = []\n",
    "\n",
    "# DataFrame pour stocker les prédictions pour chaque variable cible\n",
    "Y_pred_GB = pd.DataFrame()\n",
    "\n",
    "# Créer le dossier pour les modèles si il n'existe pas\n",
    "output_dir = 'Best_models/X_L/GB'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Boucle sur chaque variable de sortie (chaque colonne de Y_train)\n",
    "for i, col in enumerate(Y_train.columns):\n",
    "    # Initialiser un modèle de GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    \n",
    "    # Configurer la recherche de grille\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=gbr,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_percentage_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Ajuster le modèle sur la colonne actuelle de Y_train\n",
    "    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])\n",
    "    \n",
    "    # Enregistrer le meilleur modèle pour la variable cible actuelle\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[col] = best_model\n",
    "    \n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_pred = best_model.predict(X_test_transformed)\n",
    "    y_true = Y_test.iloc[:, i]\n",
    "    \n",
    "    # Ajouter les prédictions au DataFrame Y_pred_GB\n",
    "    Y_pred_GB[col] = y_pred\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Ajouter les meilleurs paramètres et les scores dans la liste des meilleurs paramètres\n",
    "    best_params_list.append({\n",
    "        'Variable': col,\n",
    "        'n_estimators': grid_search.best_params_['n_estimators'],\n",
    "        'learning_rate': grid_search.best_params_['learning_rate'],\n",
    "        'max_depth': grid_search.best_params_['max_depth'],\n",
    "        'Best Score (MAPE Negatif)': grid_search.best_score_,\n",
    "        'MSE': mse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    })\n",
    "    \n",
    "    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié\n",
    "    model_path = os.path.join(output_dir, f'{col}_best_model_GBR.joblib')  # Sauvegarder dans le bon dossier\n",
    "    dump(best_model, model_path)\n",
    "    print(f\"Modèle pour la variable '{col}' enregistré sous {model_path}\")\n",
    "\n",
    "    # Afficher les meilleurs hyperparamètres et les scores pour la variable cible actuelle\n",
    "    print(f\"Variable de sortie '{col}'\")\n",
    "    print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "    print(\"Meilleur score (MAPE négatif) :\", grid_search.best_score_)\n",
    "    print(f\"MSE: {mse}, MAPE: {mape}, R²: {r2}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Créer un DataFrame pour stocker les meilleurs paramètres et les métriques de chaque modèle\n",
    "params_GB = pd.DataFrame(best_params_list)\n",
    "\n",
    "# Afficher le DataFrame des meilleurs paramètres\n",
    "#print(params_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f5c8b",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eac9af-3f26-459c-8a80-d06cc986f11c",
   "metadata": {},
   "source": [
    "### Définition\n",
    "XGBoost est une implémentation avancée et optimisée de la méthode Gradient Boosting. Elle est conçue pour être :\n",
    "- **Rapide** grâce à des optimisations matérielles et algorithmiques.\n",
    "- **Précise** avec des techniques intégrées de régularisation.\n",
    "\n",
    "---\n",
    "\n",
    "### Modèle mathématique\n",
    "\n",
    "L'objectif est de minimiser une fonction de perte régulière définie par : \n",
    "\n",
    "$ \\mathcal{L}(\\Theta) = \\sum_{i=1}^{n} L(Y_i, \\hat{Y}_i) + \\sum_{k=1}^{K} \\Omega(f_k) $\n",
    "- $L(Y_i, \\hat{Y}_i)$ : Fonction de perte\n",
    "- $\\Omega(f_k)$ : Terme de régularisation pour éviter le surapprentissage.\n",
    "\n",
    "$ \\Omega(f_k) = \\gamma T + \\frac{1}{2} \\lambda ||w||^2 $\n",
    "  - $T$ : Nombre de feuilles dans l'arbre.\n",
    "  - $w$ : Poids des feuilles.\n",
    "  - $\\gamma, \\lambda$ : Hyperparamètres de régularisation.\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparamètres clés\n",
    "- **Nombre d'estimateurs** $(n\\_estimators)$ : Nombre total d'arbres.\n",
    "- **Taux d'apprentissage** $(learning\\_rate)$ : Contrôle la contribution de chaque arbre.\n",
    "- **Profondeur maximale** $(max\\_depth)$ : Limite la complexité des arbres.\n",
    "- **Subsample** et **ColSampleByTree** : Contrôle du sous-échantillonnage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c210111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle pour la variable 'CR' enregistré sous Best_models/X_L/XGB\\CR_best_model_XGB.joblib\n",
      "Target Column 'CR'\n",
      "Best Parameters: {'colsample_bytree': 1, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "MSE: 0.04624872366978813, MAPE: 0.26213562194069123, R²: -1.4515705263303182\n",
      "----------------------------------------\n",
      "Modèle pour la variable 'BAE' enregistré sous Best_models/X_L/XGB\\BAE_best_model_XGB.joblib\n",
      "Target Column 'BAE'\n",
      "Best Parameters: {'colsample_bytree': 1, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "MSE: 12.741706877760201, MAPE: 0.7348624062777284, R²: -0.5838825352147683\n",
      "----------------------------------------\n",
      "  Target Column  n_estimators  learning_rate  max_depth  subsample  \\\n",
      "0            CR           500           0.05          7        0.8   \n",
      "1           BAE           500           0.05          7        0.8   \n",
      "\n",
      "   colsample_bytree        MSE      MAPE        R2  \n",
      "0                 1   0.046249  0.262136 -1.451571  \n",
      "1                 1  12.741707  0.734862 -0.583883  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import pandas as pd\n",
    "from joblib import dump  # Importation de joblib pour sauvegarder les modèles\n",
    "\n",
    "# Paramètres pour GridSearchCV pour XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],  # Nombre d'arbres\n",
    "    'learning_rate': [0.05, 0.1, 0.3],  # Taux d'apprentissage\n",
    "    'max_depth': [3, 5, 7],  # Profondeur maximale des arbres\n",
    "    'subsample': [0.8, 1],  # Fraction des échantillons utilisés pour entraîner chaque arbre\n",
    "    'colsample_bytree': [0.8, 1]  # Fraction des caractéristiques utilisées pour chaque arbre\n",
    "}\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible\n",
    "best_models = {}\n",
    "best_params_list = []\n",
    "\n",
    "# Créer le dossier pour les modèles si il n'existe pas\n",
    "output_dir = 'Best_models/X_L/XGB'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Boucle sur chaque variable cible (chaque colonne de Y_train)\n",
    "for i, col in enumerate(Y_train.columns):\n",
    "    # Initialiser un modèle XGBoost\n",
    "    xgbr = XGBRegressor(objective='reg:squarederror', n_jobs=-1)  # Configuré pour minimiser l'erreur quadratique\n",
    "\n",
    "    # Configurer la recherche de grille\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgbr,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_percentage_error',  # Optimisation avec MAPE\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Ajuster le modèle sur la colonne actuelle de Y_train\n",
    "    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])\n",
    "\n",
    "    # Obtenir le meilleur modèle\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[col] = best_model\n",
    "\n",
    "    # Prédire sur les données de test\n",
    "    y_pred = best_model.predict(X_test_transformed[:k, :])\n",
    "    y_true = Y_test.iloc[:k, i]\n",
    "\n",
    "    # Calculer les erreurs\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Stocker les résultats\n",
    "    best_params_list.append({\n",
    "        'Target Column': col,\n",
    "        'n_estimators': grid_search.best_params_['n_estimators'],\n",
    "        'learning_rate': grid_search.best_params_['learning_rate'],\n",
    "        'max_depth': grid_search.best_params_['max_depth'],\n",
    "        'subsample': grid_search.best_params_['subsample'],\n",
    "        'colsample_bytree': grid_search.best_params_['colsample_bytree'],\n",
    "        'MSE': mse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié\n",
    "    model_path = os.path.join(output_dir, f'{col}_best_model_XGB.joblib')  # Sauvegarder dans le bon dossier\n",
    "    dump(best_model, model_path)\n",
    "    print(f\"Modèle pour la variable '{col}' enregistré sous {model_path}\")\n",
    "\n",
    "    # Afficher les résultats pour chaque colonne\n",
    "    print(f\"Target Column '{col}'\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(f\"MSE: {mse}, MAPE: {mape}, R²: {r2}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Créer un DataFrame pour résumer les résultats\n",
    "params_XGB = pd.DataFrame(best_params_list)\n",
    "\n",
    "# Afficher le tableau des résultats\n",
    "print(params_XGB)\n",
    "\n",
    "# Créer un DataFrame pour les prédictions\n",
    "Y_pred_XGB = pd.DataFrame()\n",
    "for column, model in best_models.items():\n",
    "    Y_pred_XGB[column] = model.predict(X_test_transformed[:k, :])\n",
    "\n",
    "# Afficher les prédictions (si nécessaire)\n",
    "# print(Y_pred_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f3dcb",
   "metadata": {},
   "source": [
    "## ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e7fe1-c416-443e-affe-90d566f1e4e4",
   "metadata": {},
   "source": [
    "### Définition\n",
    "Les **réseaux de neurones artificiels** (ANN) sont des modèles inspirés du cerveau humain, capables de détecter des motifs complexes dans les données. Ils sont constitués de couches de **neurones** interconnectés, organisées en trois types principaux de couches :\n",
    "- **Entrée** : Reçoit les données d'entrée.\n",
    "- **Cachées** : Effectuent les transformations et calculs complexes.\n",
    "- **Sortie** : Produit les prédictions finales.\n",
    "\n",
    "---\n",
    "\n",
    "### Modèle mathématique\n",
    "\n",
    "Chaque neurone dans une couche effectue un calcul basé sur une somme pondérée des entrées, suivie d'une activation non linéaire :\n",
    "\n",
    "$ z = \\sum_{i=1}^{n} w_i x_i + b $\n",
    "\n",
    "$a = \\phi(z)$\n",
    "- $w_i$ : Poids associés aux entrées.\n",
    "- $x_i$ : Entrées.\n",
    "- $b$ : Biais.\n",
    "- $\\phi$ : Fonction d'activation (ex. ReLU, sigmoïde, tanh).\n",
    "\n",
    "Les poids et les biais sont ajustés pendant l'entraînement pour minimiser une fonction de perte.\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparamètres clés\n",
    "\n",
    "- **hidden_layer_sizes** : Détermine la structure des couches cachées. Chaque tuple dans cette liste représente le nombre de neurones dans chaque couche cachée.\n",
    "- **activation** : Fonction d'activation à utiliser dans les couches cachées.\n",
    "- **learning_rate_init** : Taux d'apprentissage initial, contrôlant la vitesse à laquelle le modèle ajuste ses poids.\n",
    "- **max_iter** : Nombre maximal d'itérations (ou d'époques) pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "974cf1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle pour la variable 'CR' enregistré sous Best_models/X_L/ANN\\CR_best_model_ANN.joblib\n",
      "Target Column 'CR'\n",
      "Best Parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "MSE: 0.005470027392749603, MAPE: 0.10479160324567498, R²: 0.7100426374999715\n",
      "----------------------------------------\n",
      "Modèle pour la variable 'BAE' enregistré sous Best_models/X_L/ANN\\BAE_best_model_ANN.joblib\n",
      "Target Column 'BAE'\n",
      "Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "MSE: 2.015755500063664, MAPE: 0.374247597886475, R²: 0.7494276110379976\n",
      "----------------------------------------\n",
      "  Target Column hidden_layer_sizes activation  learning_rate_init  max_iter  \\\n",
      "0            CR           (50, 50)       relu                0.01       500   \n",
      "1           BAE           (50, 50)       tanh                0.01       500   \n",
      "\n",
      "        MSE      MAPE        R2  \n",
      "0  0.005470  0.104792  0.710043  \n",
      "1  2.015756  0.374248  0.749428  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from joblib import dump  # Importation de joblib pour sauvegarder les modèles\n",
    "\n",
    "# Paramètres pour GridSearchCV pour MLPRegressor (ANN)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],  # Architectures des couches cachées\n",
    "    'activation': ['relu', 'tanh'],                               # Fonctions d'activation\n",
    "    'learning_rate_init': [0.001, 0.01],                          # Taux d'apprentissage initial\n",
    "    'max_iter': [500, 1000]                                       # Nombre maximal d'itérations\n",
    "}\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible\n",
    "best_models = {}\n",
    "best_params_list = []\n",
    "\n",
    "# Créer le dossier pour les modèles si il n'existe pas\n",
    "output_dir = 'Best_models/X_L/ANN'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Boucle sur chaque variable cible (chaque colonne de Y_train)\n",
    "for i, col in enumerate(Y_train.columns):\n",
    "    # Initialiser un modèle ANN (MLPRegressor)\n",
    "    mlp = MLPRegressor(random_state=42)\n",
    "\n",
    "    # Configurer la recherche de grille\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=mlp,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_percentage_error',  # Optimisation avec MAPE\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Ajuster le modèle sur la colonne actuelle de Y_train\n",
    "    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])\n",
    "\n",
    "    # Obtenir le meilleur modèle\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[col] = best_model\n",
    "\n",
    "    # Prédire sur les données de test\n",
    "    y_pred = best_model.predict(X_test_transformed[:k, :])\n",
    "    y_true = Y_test.iloc[:k, i]\n",
    "\n",
    "    # Calculer les erreurs\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Stocker les résultats\n",
    "    best_params_list.append({\n",
    "        'Target Column': col,\n",
    "        'hidden_layer_sizes': grid_search.best_params_['hidden_layer_sizes'],\n",
    "        'activation': grid_search.best_params_['activation'],\n",
    "        'learning_rate_init': grid_search.best_params_['learning_rate_init'],\n",
    "        'max_iter': grid_search.best_params_['max_iter'],\n",
    "        'MSE': mse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié\n",
    "    model_path = os.path.join(output_dir, f'{col}_best_model_ANN.joblib')  # Sauvegarder dans le bon dossier\n",
    "    dump(best_model, model_path)\n",
    "    print(f\"Modèle pour la variable '{col}' enregistré sous {model_path}\")\n",
    "\n",
    "    # Afficher les résultats pour chaque colonne\n",
    "    print(f\"Target Column '{col}'\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(f\"MSE: {mse}, MAPE: {mape}, R²: {r2}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Créer un DataFrame pour résumer les résultats\n",
    "params_ANN = pd.DataFrame(best_params_list)\n",
    "\n",
    "# Afficher le tableau des résultats\n",
    "print(params_ANN)\n",
    "\n",
    "# Créer un DataFrame pour les prédictions\n",
    "Y_pred_ANN = pd.DataFrame()\n",
    "for column, model in best_models.items():\n",
    "    Y_pred_ANN[column] = model.predict(X_test_transformed[:k, :])\n",
    "\n",
    "# Afficher les prédictions (si nécessaire)\n",
    "# print(Y_pred_ANN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
