





import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
import numpy as np

import os
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.kernel_ridge import KernelRidge
from sklearn.metrics import mean_absolute_error, max_error, mean_absolute_percentage_error

import math

from xgboost import XGBRegressor
from sklearn.neural_network import MLPRegressor

from sklearn.preprocessing import PowerTransformer
import h5py
from keras.models import load_model

import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_excel('./df_cleaned.xlsx')


X = df.iloc[:, :23]  # données particules
Y = df.iloc[:,23:31]  # données optiques
L = df.iloc[:,31:]  # données Lidar





import matplotlib.pyplot as plt
import numpy as np
import os

def plot_prediction(Y_test, predictions, figsize, im_name):
    # Nombre de graphiques à afficher par ligne
    n_cols = 3
    n_rows = (len(Y_test.columns) + n_cols - 1) // n_cols  # Calculer le nombre de lignes nécessaires
    
    # Créer une figure avec n sous-graphiques (grilles de graphiques)
    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)
    
    # Aplatir les axes si plus de 1 ligne
    axes = axes.flatten()
    
    # Boucle sur chaque variable cible
    for idx, col in enumerate(Y_test.columns):
        ax = axes[idx]  # Sélectionner le subplot (graphique)
        
        # Tracer les valeurs réelles vs prédictions pour chaque modèle
        for model_name, pred_df in predictions.items():
            ax.scatter(Y_test[col].values, pred_df[col].values, label=f'{model_name}', alpha=0.6, s=30)
    
        # Tracer une ligne de référence y = x pour voir la correspondance entre valeurs réelles et prédictions
        x_range = np.linspace(min(Y_test[col].min(), pred_df[col].min()), max(Y_test[col].max(), pred_df[col].max()), 100)
        ax.plot(x_range, x_range, linestyle="--", color="black", label="y = x")
    
        # Ajouter le titre et les légendes
        ax.set_title(f'Comparison of ground truth and prediction for: {col}', fontsize=10)
        ax.set_xlabel(f'Ground truth {col}', fontsize=8)
        ax.set_ylabel(f'Predictions {col}', fontsize=8)
        ax.legend(fontsize=8)
        ax.grid(True)
    
    # Supprimer les axes inutilisés (si le nombre d'axes est supérieur au nombre de graphiques)
    for idx in range(len(Y_test.columns), len(axes)):
        fig.delaxes(axes[idx])

    # Ajuster l'espace entre les graphiques
    plt.tight_layout()
    
    # Chemin pour sauvegarder l'image
    output_dir = "../Images_finales"  # Nom du dossier
    if not os.path.exists(output_dir):  # Créer le dossier s'il n'existe pas
        os.makedirs(output_dir)
    
    output_path = os.path.join(output_dir, im_name)  # Chemin complet du fichier
    
    # Sauvegarder le plot
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    
    plt.show()
    
    print(f"Graphique sauvegardé dans : {output_path}")


def plot_residus(Y_test,predictions,figsize) : 
    n_cols = 3
    n_rows = (len(Y_test.columns) + n_cols - 1) // n_cols 
    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)

    # Aplatir les axes si plus de 1 ligne
    axes = axes.flatten()
    
    # Boucle sur chaque variable cible
    for idx, col in enumerate(Y_test.columns):
        ax = axes[idx]  # Sélectionner le subplot (graphique)
    
        # Tracer les résidus pour chaque modèle
        for model_name, pred_df in predictions.items():
            residuals = Y_test[col].values - pred_df[col].values  # Calcul des résidus
            ax.scatter(Y_test[col].values, residuals, label=f'{model_name}', alpha=0.6, s=30)
        
        # Ajouter une ligne horizontale y = 0 pour référence
        ax.axhline(0, color='black', linestyle='--', linewidth=2, label='y = 0')
    
        # Ajouter le titre et les légendes
        ax.set_title(f'Residuals graph of: {col}', fontsize=10)
        ax.set_xlabel(f'Valeurs réelles {col}', fontsize=8)
        ax.set_ylabel('Residuals', fontsize=8)
        ax.legend(fontsize=8)
        ax.grid(True)
    
    # Ajuster l'espace entre les graphiques
    plt.tight_layout()
    
    # Afficher les graphiques
    plt.show()


# Fonction pour mettre en évidence la meilleure valeur par ligne
def highlight_best_by_row(data, higher_is_better=False):
    # Initialiser un DataFrame vide pour stocker les styles
    styles = pd.DataFrame('', index=data.index, columns=data.columns)
    
    # Identifier la meilleure colonne pour chaque ligne
    if higher_is_better:
        best_columns = data.idxmax(axis=1)  # Colonne avec la valeur maximale
    else:
        best_columns = data.idxmin(axis=1)  # Colonne avec la valeur minimale
    
    # Appliquer le style uniquement à la meilleure valeur par ligne
    for idx, col in best_columns.items():
        styles.loc[idx, col] = 'background-color: lightgreen'
    
    return styles





from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
pt = PowerTransformer(method='yeo-johnson')

X_test=X.reset_index(drop=True)
Y_test=L.reset_index(drop=True)


X_test_transformed = scaler.fit_transform(X_test)  #pt.fit_transform(X_train)
Y_test_transformed = pd.DataFrame(Y_test, columns=Y_test.columns)





from joblib import load  # Pour charger les modèles enregistrés
import os
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score

# Dossier où les modèles ont été enregistrés
output_dir = 'Best_models/X_L_final/'

# Initialisation des DataFrames pour les prédictions
Y_pred_XL_KRR = pd.DataFrame()
Y_pred_XL_GB = pd.DataFrame()
Y_pred_XL_XGB = pd.DataFrame()
Y_pred_XL_ANN = pd.DataFrame()

# Liste des modèles à charger
model_names = ['KRR', 'GB', 'XGB', 'ANN']  # Ajoutez ici les modèles que vous avez enregistrés

# Initialisation des dictionnaires pour stocker les erreurs
errors_KRR = {}
errors_GB = {}
errors_XGB = {}
errors_ANN = {}

# Charger et prédire avec chaque modèle enregistré
for model_name in model_names:
    model_path = os.path.join(output_dir, model_name)
    
    model_files = [f for f in os.listdir(model_path) if f.endswith('.joblib')]
    
    # Initialisation des dictionnaires pour les prédictions
    y_pred = {}
    var = []
    
    for model_file in model_files:
        # Extraire le nom de la variable cible à partir du nom du fichier
        variable_name = model_file.split(f'_best_model_{model_name}')[0]
        var.append(variable_name)
        
        # Charger le modèle
        model = load(os.path.join(model_path, model_file))

        # Effectuer les prédictions pour chaque variable
        y_pred[variable_name] = model.predict(X_test_transformed)  # Prédictions pour chaque variable
        
        # Calculer les erreurs
        mse = mean_squared_error(Y_test[variable_name], y_pred[variable_name])
        mape = mean_absolute_percentage_error(Y_test[variable_name], y_pred[variable_name])
        r2 = r2_score(Y_test[variable_name], y_pred[variable_name])
        
        # Stocker les erreurs
        if model_name == 'KRR':
            errors_KRR[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'GB':
            errors_GB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'XGB':
            errors_XGB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'ANN':
            errors_ANN[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
    
    # Convertir les prédictions en DataFrame
    y_pred_df = pd.DataFrame(y_pred, columns=var)
        
    # Ajouter les prédictions au DataFrame correspondant au modèle
    if model_name == 'KRR':
        Y_pred_XL_KRR = y_pred_df  # Assigner les prédictions au bon DataFrame
    elif model_name == 'GB':
        Y_pred_XL_GB = y_pred_df
    elif model_name == 'XGB':
        Y_pred_XL_XGB = y_pred_df
    elif model_name == 'ANN':
        Y_pred_XL_ANN = y_pred_df

df_errors_XL_KRR = pd.DataFrame(errors_KRR).T[['MSE', 'MAPE', 'R2']]
df_errors_XL_GB = pd.DataFrame(errors_GB).T[['MSE', 'MAPE', 'R2']]
df_errors_XL_XGB = pd.DataFrame(errors_XGB).T[['MSE', 'MAPE', 'R2']]
df_errors_XL_ANN = pd.DataFrame(errors_ANN).T[['MSE', 'MAPE', 'R2']]






import numpy as np
import matplotlib.pyplot as plt

# Dictionnaire contenant les prédictions de chaque modèle
# Vous allez ajouter les prédictions depuis prediction_X_L ici
predictions_XL = {
    'KRR': Y_pred_XL_KRR,  # Remplacer par les prédictions issues de prediction_X_L
    'GB': Y_pred_XL_GB,
    'XGB': Y_pred_XL_XGB,
    'ANN': Y_pred_XL_ANN  # Si vous avez d'autres modèles, vous pouvez les ajouter ici
}

plot_prediction(Y_test,predictions_XL,figsize =((12,5)),im_name = 'X_L_results.png')








plot_residus(Y_test,predictions_XL,figsize =((12,5)))








# Remplir les dictionnaires pour MSE, MAPE et R² pour chaque modèle
results_mse = {}
results_mape = {}
results_r2 = {}

results_mse['KRR'] = df_errors_XL_KRR['MSE']
results_mape['KRR'] = df_errors_XL_KRR['MAPE']
results_r2['KRR'] = df_errors_XL_KRR['R2']

results_mse['GB'] = df_errors_XL_GB['MSE']
results_mape['GB'] = df_errors_XL_GB['MAPE']
results_r2['GB'] = df_errors_XL_GB['R2']

results_mse['XGB'] = df_errors_XL_XGB['MSE']
results_mape['XGB'] = df_errors_XL_XGB['MAPE']
results_r2['XGB'] = df_errors_XL_XGB['R2']

results_mse['ANN'] = df_errors_XL_ANN['MSE']
results_mape['ANN'] = df_errors_XL_ANN['MAPE']
results_r2['ANN'] = df_errors_XL_ANN['R2']

# Créer les DataFrames pour chaque métrique
df_mse = pd.DataFrame(results_mse)
df_mape = pd.DataFrame(results_mape)
df_r2 = pd.DataFrame(results_r2)


# Appliquer le style avec la fonction mise à jour
styled_mse = df_mse.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MSE : Meilleure méthode pour chaque paramètre")
styled_mape = df_mape.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MAPE : Meilleure méthode pour chaque paramètre")
styled_r2 = df_r2.style.apply(highlight_best_by_row, higher_is_better=True, axis=None).set_caption("R² : Meilleure méthode pour chaque paramètre")

# Afficher les tableaux
from IPython.display import display
display(styled_mse)
display(styled_mape)
display(styled_r2)





from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_test=X.reset_index(drop=True)
Y_test=Y.reset_index(drop=True)

X_test_transformed =  scaler.fit_transform(X_test)   #pt.transform(X_test)
Y_test_transformed = pd.DataFrame(Y_test, columns=Y_test.columns)





from joblib import load  # Pour charger les modèles enregistrés
import os
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score

# Dossier où les modèles ont été enregistrés
output_dir = 'Best_models/X_Y_final/'

# Initialisation des DataFrames pour les prédictions
Y_pred_XY_KRR = pd.DataFrame()
Y_pred_XY_GB = pd.DataFrame()
Y_pred_XY_XGB = pd.DataFrame()
Y_pred_XY_ANN = pd.DataFrame()

# Liste des modèles à charger
model_names = ['KRR', 'GB', 'XGB', 'ANN']  # Ajoutez ici les modèles que vous avez enregistrés

# Initialisation des dictionnaires pour stocker les erreurs
errors_KRR = {}
errors_GB = {}
errors_XGB = {}
errors_ANN = {}

# Charger et prédire avec chaque modèle enregistré
for model_name in model_names:
    model_path = os.path.join(output_dir, model_name)
    
    model_files = [f for f in os.listdir(model_path) if f.endswith('.joblib')]
    
    # Initialisation des dictionnaires pour les prédictions
    y_pred = {}
    var = []
    
    for model_file in model_files:
        # Extraire le nom de la variable cible à partir du nom du fichier
        variable_name = model_file.split(f'_best_model_{model_name}')[0]
        var.append(variable_name)
        
        # Charger le modèle
        model = load(os.path.join(model_path, model_file))
    
        # Effectuer les prédictions pour chaque variable
        y_pred[variable_name] = model.predict(X_test_transformed)  # Prédictions pour chaque variable
        
        # Calculer les erreurs
        mse = mean_squared_error(Y_test[variable_name], y_pred[variable_name])
        mape = mean_absolute_percentage_error(Y_test[variable_name], y_pred[variable_name])
        r2 = r2_score(Y_test[variable_name], y_pred[variable_name])
        
        # Stocker les erreurs
        if model_name == 'KRR':
            errors_KRR[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'GB':
            errors_GB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'XGB':
            errors_XGB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'ANN':
            errors_ANN[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
    
    # Convertir les prédictions en DataFrame
    y_pred_df = pd.DataFrame(y_pred, columns=var)
        
    # Ajouter les prédictions au DataFrame correspondant au modèle
    if model_name == 'KRR':
        Y_pred_XY_KRR = y_pred_df  # Assigner les prédictions au bon DataFrame
    elif model_name == 'GB':
        Y_pred_XY_GB = y_pred_df
    elif model_name == 'XGB':
        Y_pred_XY_XGB = y_pred_df
    elif model_name == 'ANN':
        Y_pred_XY_ANN = y_pred_df

df_errors_XY_KRR = pd.DataFrame(errors_KRR).T[['MSE', 'MAPE', 'R2']]
df_errors_XY_GB = pd.DataFrame(errors_GB).T[['MSE', 'MAPE', 'R2']]
df_errors_XY_XGB = pd.DataFrame(errors_XGB).T[['MSE', 'MAPE', 'R2']]
df_errors_XY_ANN = pd.DataFrame(errors_ANN).T[['MSE', 'MAPE', 'R2']]






import numpy as np
import matplotlib.pyplot as plt

# Dictionnaire contenant les prédictions de chaque modèle
# Vous allez ajouter les prédictions depuis prediction_X_L ici
predictions_XY = {
    'KRR': Y_pred_XY_KRR,  # Remplacer par les prédictions issues de prediction_X_L
    'GB': Y_pred_XY_GB,
    'XGB': Y_pred_XY_XGB,
    'ANN': Y_pred_XY_ANN  # Si vous avez d'autres modèles, vous pouvez les ajouter ici
}


plot_prediction(Y_test,predictions_XY,figsize =((15,10)),im_name = 'X_Y_results.png')








plot_residus(Y_test,predictions_XY,figsize =((15,10)))








results_mse['KRR'] = df_errors_XY_KRR['MSE']
results_mape['KRR'] = df_errors_XY_KRR['MAPE']
results_r2['KRR'] = df_errors_XY_KRR['R2']

results_mse['GB'] = df_errors_XY_GB['MSE']
results_mape['GB'] = df_errors_XY_GB['MAPE']
results_r2['GB'] = df_errors_XY_GB['R2']

results_mse['XGB'] = df_errors_XY_XGB['MSE']
results_mape['XGB'] = df_errors_XY_XGB['MAPE']
results_r2['XGB'] = df_errors_XY_XGB['R2']

results_mse['ANN'] = df_errors_XY_ANN['MSE']
results_mape['ANN'] = df_errors_XY_ANN['MAPE']
results_r2['ANN'] = df_errors_XY_ANN['R2']

# Créer les DataFrames pour chaque métrique
df_mse = pd.DataFrame(results_mse)
df_mape = pd.DataFrame(results_mape)
df_r2 = pd.DataFrame(results_r2)


# Appliquer le style avec la fonction mise à jour
styled_mse = df_mse.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MSE : Meilleure méthode pour chaque paramètre")
styled_mape = df_mape.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MAPE : Meilleure méthode pour chaque paramètre")
styled_r2 = df_r2.style.apply(highlight_best_by_row, higher_is_better=True, axis=None).set_caption("R² : Meilleure méthode pour chaque paramètre")

# Afficher les tableaux
from IPython.display import display
display(styled_mse)
display(styled_mape)
display(styled_r2)





from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X = df.iloc[:, 2:23]  # données particules
Y = df.iloc[:,23:31]  # données optiques
L = df.iloc[:, [0, 1] + list(range(31, df.shape[1]))]

X = X.rename(columns={'density_bc (g/cm^3)':'density_bc (g cm^3)'})
X = X.rename(columns={'density_organics (g/cm^3)':'density_organics (g cm^3)'})
X = X.rename(columns={'mr_total/bc':'mr_total bc'})
X = X.rename(columns={'mr_nonBC/BC':'mr_nonBC BC'})

# Sélection des variables intéressantes 
variables = ['primary_particle_size (nm)', 
             'vol_equi_radius_outer (nm)', 
             'vol_equi_radius_inner (nm)', 
             'equi_mobility_dia (nm)',
                "mass_bc (g)"]

X = X[variables]

X_test=L.reset_index(drop=True)
Y_test=X.reset_index(drop=True)

X_test_transformed =  scaler.fit_transform(X_test)   #pt.transform(X_test)
Y_test_transformed = pd.DataFrame(Y_test, columns=Y_test.columns)





from joblib import load  # Pour charger les modèles enregistrés
import os
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score

# Dossier où les modèles ont été enregistrés
output_dir = 'Best_models/L_X_final/'

# Initialisation des DataFrames pour les prédictions
Y_pred_LX_KRR = pd.DataFrame()
Y_pred_LX_GB = pd.DataFrame()
Y_pred_LX_XGB = pd.DataFrame()
Y_pred_LX_ANN = pd.DataFrame()


# Liste des modèles à charger
model_names = ['KRR', 'GB', 'XGB', 'ANN']  # Ajoutez ici les modèles que vous avez enregistrés

# Initialisation des dictionnaires pour stocker les erreurs
errors_KRR = {}
errors_GB = {}
errors_XGB = {}
errors_ANN = {}

# Charger et prédire avec chaque modèle enregistré
for model_name in model_names:
    model_path = os.path.join(output_dir, model_name)
    
    model_files = [f for f in os.listdir(model_path) if f.endswith('.joblib')]
    
    # Initialisation des dictionnaires pour les prédictions
    y_pred = {}
    var = []
    
    for model_file in model_files:
        # Extraire le nom de la variable cible à partir du nom du fichier
        variable_name = model_file.split(f'_best_model_{model_name}')[0]
        var.append(variable_name)
        
        # Charger le modèle
        model = load(os.path.join(model_path, model_file))
    
        # Effectuer les prédictions pour chaque variable
        y_pred[variable_name] = model.predict(X_test_transformed)  # Prédictions pour chaque variable
        
        # Calculer les erreurs
        mse = mean_squared_error(Y_test[variable_name], y_pred[variable_name])
        mape = mean_absolute_percentage_error(Y_test[variable_name], y_pred[variable_name])
        r2 = r2_score(Y_test[variable_name], y_pred[variable_name])
        
        # Stocker les erreurs
        if model_name == 'KRR':
            errors_KRR[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'GB':
            errors_GB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'XGB':
            errors_XGB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'ANN':
            errors_ANN[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
    
    # Convertir les prédictions en DataFrame
    y_pred_df = pd.DataFrame(y_pred, columns=var)
        
    # Ajouter les prédictions au DataFrame correspondant au modèle
    if model_name == 'KRR':
        Y_pred_LX_KRR = y_pred_df  # Assigner les prédictions au bon DataFrame
    elif model_name == 'GB':
        Y_pred_LX_GB = y_pred_df
    elif model_name == 'XGB':
        Y_pred_LX_XGB = y_pred_df
    elif model_name == 'ANN':
        Y_pred_LX_ANN = y_pred_df

df_errors_LX_KRR = pd.DataFrame(errors_KRR).T[['MSE', 'MAPE', 'R2']]
df_errors_LX_GB = pd.DataFrame(errors_GB).T[['MSE', 'MAPE', 'R2']]
df_errors_LX_XGB = pd.DataFrame(errors_XGB).T[['MSE', 'MAPE', 'R2']]
df_errors_LX_ANN = pd.DataFrame(errors_ANN).T[['MSE', 'MAPE', 'R2']]






predictions_LX = {
    'KRR': Y_pred_LX_KRR,  # Remplacer par les prédictions issues de prediction_X_L
    'GB': Y_pred_LX_GB,
    'XGB': Y_pred_LX_XGB,
    'ANN': Y_pred_LX_ANN  # Si vous avez d'autres modèles, vous pouvez les ajouter ici
}

plot_prediction(Y_test,predictions_LX,figsize =((20,12)),im_name = 'L_X_results.png')





plot_residus(Y_test,predictions_LX,figsize =((15,10)))





results_mse['KRR'] = df_errors_LX_KRR['MSE']
results_mape['KRR'] = df_errors_LX_KRR['MAPE']
results_r2['KRR'] = df_errors_LX_KRR['R2']

results_mse['GB'] = df_errors_LX_GB['MSE']
results_mape['GB'] = df_errors_LX_GB['MAPE']
results_r2['GB'] = df_errors_LX_GB['R2']

results_mse['XGB'] = df_errors_LX_XGB['MSE']
results_mape['XGB'] = df_errors_LX_XGB['MAPE']
results_r2['XGB'] = df_errors_LX_XGB['R2']

results_mse['ANN'] = df_errors_LX_ANN['MSE']
results_mape['ANN'] = df_errors_LX_ANN['MAPE']
results_r2['ANN'] = df_errors_LX_ANN['R2']

# Créer les DataFrames pour chaque métrique
df_mse = pd.DataFrame(results_mse)
df_mape = pd.DataFrame(results_mape)
df_r2 = pd.DataFrame(results_r2)


# Appliquer le style avec la fonction mise à jour
styled_mse = df_mse.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MSE : Meilleure méthode pour chaque paramètre")
styled_mape = df_mape.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MAPE : Meilleure méthode pour chaque paramètre")
styled_r2 = df_r2.style.apply(highlight_best_by_row, higher_is_better=True, axis=None).set_caption("R² : Meilleure méthode pour chaque paramètre")

# Afficher les tableaux
from IPython.display import display
display(styled_mse)
display(styled_mape)
display(styled_r2)





X = df.iloc[:, 2:23]  # données particules
L = df.iloc[:, [0, 1] + list(range(31, df.shape[1]))]

# Sélection des variables intéressantes 
variables = ['primary_particle_size (nm)', 
             'vol_equi_radius_outer (nm)', 
             'vol_equi_radius_inner (nm)', 
             'equi_mobility_dia (nm)',
                "mass_bc (g)"]

X = X[variables]



X_test=L.reset_index(drop=True)
Y_test=X.reset_index(drop=True)

X_test_transformed =  scaler.fit_transform(X_test)   #pt.transform(X_test)
Y_test_transformed = pd.DataFrame(Y_test, columns=Y_test.columns)








from joblib import load  # Pour charger les modèles enregistrés
import os
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score

# Dossier où les modèles ont été enregistrés
output_dir = '../Best_model/L_X_1_var/'

# Initialisation des DataFrames pour les prédictions
Y_pred_XL_KRR = pd.DataFrame()
Y_pred_XL_GB = pd.DataFrame()

# Liste des modèles à charger (uniquement KRR et GB)
model_names = ['KRR','GB']  # Nous avons gardé seulement les modèles KRR et GB

# Initialisation des dictionnaires pour stocker les erreurs
errors_KRR = {}
errors_GB = {}

# Charger et prédire avec chaque modèle enregistré
for model_name in model_names:
    model_path = os.path.join(output_dir, model_name)
    
    model_files = [f for f in os.listdir(model_path) if f.endswith('.joblib')]
    
    # Initialisation des dictionnaires pour les prédictions
    y_pred = {}
    var = []
    
    for model_file in model_files:
        # Extraire le nom de la variable cible à partir du nom du fichier
        base_name = model_file.replace('.joblib', '')
        
        # Extraire la cible (avant "_best_model") et la variable prédictive (après "_avec_")
        variable_name = base_name.split('_best_model')[0]  # La partie avant "_best_model"
        predictive_variable = base_name.split('_avec_')[-1]  # La partie après "_avec_"
        
        # Extraire le type de modèle (entre "_best_model" et "_avec_")
        model_type = base_name.split('_best_model')[1].split('_avec_')[0] 
        var.append(predictive_variable)
        # Charger le modèle
        model = load(os.path.join(model_path, model_file))

        # Effectuer les prédictions pour chaque variable
        x_input = X_test[[predictive_variable]]
        x_input_transformed =  scaler.fit_transform(x_input) 
        y_pred= model.predict(x_input_transformed)  # Prédictions pour chaque variable
        # Calculer les erreurs
        mse = mean_squared_error(Y_test[[variable_name]], y_pred)
        mape = mean_absolute_percentage_error(Y_test[[variable_name]], y_pred)
        r2 = r2_score(Y_test[[variable_name]], y_pred)
        
        # Stocker les erreurs dans les dictionnaires respectifs
        if model_name == 'KRR':
            errors_KRR[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_name == 'GB':
            errors_GB[variable_name] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
    
        # Convertir les prédictions en DataFrame
        y_pred_df[variable_name] = y_pred

    # Ajouter les prédictions au DataFrame correspondant au modèle
    if model_name == 'KRR':
        Y_pred_XL_KRR = y_pred_df  # Assigner les prédictions au bon DataFrame
    elif model_name == 'GB':
        Y_pred_XL_GB = y_pred_df

# Convertir les erreurs en DataFrames
df_errors_XL_KRR = pd.DataFrame(errors_KRR).T[['MSE', 'MAPE', 'R2']]
df_errors_XL_GB = pd.DataFrame(errors_GB).T[['MSE', 'MAPE', 'R2']]


new_order = ['equi_mobility_dia (nm)', 'mass_bc (g)', 'primary_particle_size (nm)','vol_equi_radius_inner (nm)','vol_equi_radius_outer (nm)']

# Réorganiser les colonnes
Y_test= Y_test[new_order]


# Fonction pour afficher les graphiques des prédictions vs valeurs réelles
def plot_prediction(Y_test, predictions_dict, figsize,im_name):
    n_cols = 3
    n_rows = (len(Y_test.columns) + n_cols - 1) // n_cols  # Calculer le nombre de lignes nécessaires
    
    # Créer une figure avec n sous-graphiques
    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)
    axes = axes.flatten()
    
    # Boucle sur chaque variable cible
    for idx, col in enumerate(Y_test.columns):
        ax = axes[idx]  # Sélectionner le subplot correspondant
        
        # Tracer les valeurs réelles vs prédictions pour chaque modèle
        for model_name, pred_df in predictions_dict.items():
            ax.scatter(Y_test[col], pred_df[col], label=f'{model_name}', alpha=0.6, s=30)

        # Tracer une ligne de référence y = x
        min_val = min(Y_test[col].min(), *(pred_df[col].min() for pred_df in predictions_dict.values() if col in pred_df.columns))
        max_val = max(Y_test[col].max(), *(pred_df[col].max() for pred_df in predictions_dict.values() if col in pred_df.columns))
        x_range = np.linspace(min_val, max_val, 100)
        ax.plot(x_range, x_range, linestyle="--", color="black", label="y = x")

        # Ajouter le titre, les étiquettes, et la légende
        ax.set_title(f'Comparison for {col}', fontsize=10)
        ax.set_xlabel(f'Ground truth {col}', fontsize=8)
        ax.set_ylabel(f'Predictions {col}', fontsize=8)
        ax.legend(fontsize=8)
        ax.grid(True)
    
    # Supprimer les sous-graphiques inutilisés (s'il y a plus de cases que de variables)
    for idx in range(len(Y_test.columns), len(axes)):
        fig.delaxes(axes[idx])
    
    plt.tight_layout()
    # Chemin pour sauvegarder l'image
    output_dir = "../Images_finales"  # Nom du dossier
    if not os.path.exists(output_dir):  # Créer le dossier s'il n'existe pas
        os.makedirs(output_dir)
    
    output_path = os.path.join(output_dir, im_name)  # Chemin complet du fichier
    
    # Sauvegarder le plot
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    
    print(f"Graphique sauvegardé dans : {output_path}")
    
    plt.show()


# Appeler la fonction pour afficher les graphiques
predictions_dict = {
    'KRR': Y_pred_XL_KRR,
    'GB' : Y_pred_XL_GB
}

# Appeler la fonction pour afficher les graphiques
plot_prediction(Y_test, predictions_dict,figsize=(15, 10),im_name ='L_X_1_var.png')



df_errors_XL_GB


# Créer un DataFrame avec les R² pour chaque modèle et chaque variable
dataR2 = {
    'KRR': {key: value['R2'] for key, value in errors_KRR.items()},
    'GB': {key: value['R2'] for key, value in errors_GB.items()}
}

df_r2 = pd.DataFrame(dataR2)

dataMSE = {
    'KRR': {key: value['MSE'] for key, value in errors_KRR.items()},
    'XGB': {key: value['MSE'] for key, value in errors_GB.items()}
}

df_MSE = pd.DataFrame(dataMSE)

dataMAPE = {
    'KRR': {key: value['MAPE'] for key, value in errors_KRR.items()},
    'XGB': {key: value['MAPE'] for key, value in errors_GB.items()}
}

df_MAPE = pd.DataFrame(dataMAPE)

# Appliquer le style avec la fonction mise à jour
styled_mse = df_MSE.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MSE : Meilleure méthode pour chaque paramètre")
styled_mape = df_MAPE.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MAPE : Meilleure méthode pour chaque paramètre")
styled_r2 = df_r2.style.apply(highlight_best_by_row, higher_is_better=True, axis=None).set_caption("R² : Meilleure méthode pour chaque paramètre")

# Afficher les tableaux
from IPython.display import display
display(styled_mse)
display(styled_mape)
display(styled_r2)





import os
import json
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from joblib import load
import xgboost as xgb

# Chemin vers les fichiers de modèles
model_path = "../Best_model/L_X_2_var"

# Dictionnaire pour stocker les prédictions en fonction des modèles
predictions_LX2 = {
    'KRR': {},
    'GB': {}
}

# Dictionnaires pour stocker les erreurs
errors_KRR2 = {}
errors_XGB2 = {}
errors_ANN2 = {}

# Parcourir les fichiers de modèles
for file in os.listdir(model_path):
    if file.endswith('.joblib'):  # Traitement des modèles KRR/ANN
        base_name = file.replace('.joblib', '')
        
        # Extraire la cible (avant "_best_model") et la variable prédictive (après "_avec_")
        target_variable = base_name.split('_best_model')[0]  # La partie avant "_best_model"
        predictive_variable = base_name.split('_avec_')[-1]  # La partie après "_avec_"
        print(target_variable)
        # Extraire le type de modèle (entre "_best_model" et "_avec_")
        model_type = base_name.split('_best_model')[1].split('_avec_')[0]  # La partie entre "_best_model" et "_avec_"
        
        # Charger le modèle KRR ou ANN
        model = load(os.path.join(model_path, file))
        predictive_variable_name = predictive_variable.strip("()").replace("'", "").split(", ")
        
        # Effectuer les prédictions
        x_input = X_test[[predictive_variable_name[0],predictive_variable_name[1]]].values  # Tableau 2D
        x_input_transformed =  scaler.fit_transform(x_input) 
        y_pred = model.predict(x_input_transformed)
        
        # Stocker les prédictions dans le dictionnaire selon le modèle
        if target_variable not in predictions_LX2[model_type]:
            predictions_LX2[model_type][target_variable] = pd.Series(y_pred, name=target_variable)
        
        # Calculer les erreurs (MSE, MAPE, R2)
        mse = mean_squared_error(Y_test_transformed[target_variable], y_pred)
        mape = mean_absolute_percentage_error(Y_test_transformed[target_variable], y_pred)
        r2 = r2_score(Y_test_transformed[target_variable], y_pred)
        
        # Stocker les erreurs dans le dictionnaire approprié
        if model_type == 'KRR':
            errors_KRR[target_variable] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_type == 'ANN':
            errors_ANN[target_variable] = {'MSE': mse, 'MAPE': mape, 'R2': r2}
        elif model_type == 'XGB':
            errors_XGB[target_variable] = {'MSE': mse, 'MAPE': mape, 'R2': r2}

# Créer un DataFrame avec les R² pour chaque modèle et chaque variable
dataR2 = {
    'KRR': {key: value['R2'] for key, value in errors_KRR.items()},
    'GB': {key: value['R2'] for key, value in errors_GB.items()}
}

df_r22 = pd.DataFrame(dataR2)

dataMSE = {
    'KRR': {key: value['MSE'] for key, value in errors_KRR.items()},
    'GB': {key: value['MSE'] for key, value in errors_GB.items()}
}

df_MSE2 = pd.DataFrame(dataMSE)

dataMAPE = {
    'KRR': {key: value['MAPE'] for key, value in errors_KRR.items()},
    'GB': {key: value['MAPE'] for key, value in errors_GB.items()}
}

df_MAPE2 = pd.DataFrame(dataMAPE)



def plot_prediction(Y_test, predictions, figsize,im_name):
    n_cols = 3
    n_rows = (len(Y_test.columns) + n_cols - 1) // n_cols  # Calculer le nombre de lignes nécessaires
    
    # Créer une figure avec n sous-graphiques
    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)
    axes = axes.flatten()
    
    # Boucle sur chaque variable cible
    for idx, col in enumerate(Y_test.columns):
        ax = axes[idx]  # Sélectionner le subplot
        
        # Tracer les valeurs réelles vs prédictions pour chaque modèle
        for model_name, pred_df in predictions.items():
            if col in pred_df:  # S'assurer que la colonne est présente dans les prédictions
                # Si pred_df est une série, on n'a pas besoin d'accéder à col
                ax.scatter(Y_test[col], pred_df[col], label=f'{model_name}', alpha=0.6, s=30)

        # Tracer une ligne de référence y = x
        x_range = np.linspace(min(Y_test[col].min(), pred_df[col].min()), max(Y_test[col].max(), pred_df[col].max()), 100)
        ax.plot(x_range, x_range, linestyle="--", color="black", label="y = x")
        
        # Ajouter le titre et les légendes
        ax.set_title(f'Comparison for {col}', fontsize=10)
        ax.set_xlabel(f'Ground truth {col}', fontsize=8)
        ax.set_ylabel(f'Predictions {col}', fontsize=8)
        ax.legend(fontsize=8)
        ax.grid(True)

     # Supprimer les sous-graphiques inutilisés (s'il y a plus de cases que de variables)
    for idx in range(len(Y_test.columns), len(axes)):
        fig.delaxes(axes[idx])
        
    plt.tight_layout()
    output_dir = "../Images_finales"  # Nom du dossier
    if not os.path.exists(output_dir):  # Créer le dossier s'il n'existe pas
        os.makedirs(output_dir)
    
    output_path = os.path.join(output_dir, im_name)  # Chemin complet du fichier
    
    # Sauvegarder le plot
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    
    print(f"Graphique sauvegardé dans : {output_path}")
    
    plt.show()

# Appeler la fonction pour afficher les graphiques
plot_prediction(Y_test_transformed, predictions_LX2,figsize =(15,10),im_name ='L_X_2_var')



# Fonction pour afficher les graphiques des prédictions vs valeurs réelles
def plot_res(Y_test, predictions, figsize=(15, 10)):
    n_cols = 3
    n_rows = (len(Y_test.columns) + n_cols - 1) // n_cols  # Calculer le nombre de lignes nécessaires
    
    # Créer une figure avec n sous-graphiques
    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)
    axes = axes.flatten()
    
    # Boucle sur chaque variable cible
    for idx, col in enumerate(Y_test.columns):
        ax = axes[idx]  # Sélectionner le subplot
        
        # Tracer les valeurs réelles vs prédictions pour chaque modèle
        for model_name, pred_df in predictions.items():
            if col in pred_df:  # S'assurer que la colonne est présente dans les prédictions
                res = Y_test[col].values - pred_df[col].values
                ax.scatter(Y_test[col].values, res, label=f'{model_name}', alpha=0.6, s=30)

        # Ajouter une ligne horizontale y = 0 pour référence
        ax.axhline(0, color='black', linestyle='--', linewidth=2, label='y = 0')
    
        # Ajouter le titre et les légendes
        ax.set_title(f'Residus for {col}', fontsize=10)
        ax.set_xlabel(f'Ground truth {col}', fontsize=8)
        ax.set_ylabel(f'Residus {col}', fontsize=8)
        ax.legend(fontsize=8)
        ax.grid(True)
    
    plt.tight_layout()
    plt.show()

# Appeler la fonction pour afficher les graphiques
plot_res(Y_test_transformed, predictions_LX2)



# Appliquer le style avec la fonction mise à jour
styled_mse = df_MSE2.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MSE : Meilleure méthode pour chaque paramètre")
styled_mape = df_MAPE2.style.apply(highlight_best_by_row, higher_is_better=False, axis=None).set_caption("MAPE : Meilleure méthode pour chaque paramètre")
styled_r2 = df_r22.style.apply(highlight_best_by_row, higher_is_better=True, axis=None).set_caption("R² : Meilleure méthode pour chaque paramètre")

# Afficher les tableaux
from IPython.display import display
display(styled_mse)
display(styled_mape)
display(styled_r2)



