





import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
import numpy as np


from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.kernel_ridge import KernelRidge
from sklearn.metrics import mean_absolute_error, max_error, mean_absolute_percentage_error

import math

from xgboost import XGBRegressor
from sklearn.neural_network import MLPRegressor

from sklearn.preprocessing import PowerTransformer
import h5py
from keras.models import load_model

import matplotlib.pyplot as plt
import seaborn as sns





df = pd.read_excel('./df_cleaned.xlsx')


# changer les noms de scolonnes avec / 

# Renommer la colonne existante en 'density_bc (g/cm^3)'
df = df.rename(columns={'density_bc (g/cm^3)':'density_bc (g cm^3)'})
df = df.rename(columns={'density_organics (g/cm^3)':'density_organics (g cm^3)'})
df = df.rename(columns={'mr_total/bc':'mr_total bc'})
df = df.rename(columns={'mr_nonBC/BC':'mr_nonBC BC'})



X = df.iloc[:, 2:23]  # données particules
Y = df.iloc[:,23:31]  # données optiques
L = df.iloc[:, [0, 1] + list(range(31, df.shape[1]))]


# Sélection des variables intéressantes 
variables = ['primary_particle_size (nm)', 
             'vol_equi_radius_outer (nm)', 
             'vol_equi_radius_inner (nm)', 
             'equi_mobility_dia (nm)',
                "mass_bc (g)"]

X = X[variables]





from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()


X_train, X_test, Y_train, Y_test = train_test_split(
            L, X,
            test_size=0.30,
            random_state=10)

pt = PowerTransformer(method='yeo-johnson')

X_test=X_test.reset_index(drop=True)
Y_test=Y_test.reset_index(drop=True)


X_train_transformed = scaler.fit_transform(X_train)  #pt.fit_transform(X_train)
X_test_transformed =  scaler.fit_transform(X_test)   #pt.transform(X_test)

Y_train_transformed = pd.DataFrame(Y_train, columns=Y_train.columns)
Y_test_transformed = pd.DataFrame(Y_test, columns=Y_test.columns)


print(X_test.columns)
print(Y_test.columns)





k = 3883








import os
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
import pandas as pd
from joblib import dump  # Importation de joblib pour sauvegarder les modèles

# Initialiser le modèle de régression linéaire
linear_model = LinearRegression()

# Initialiser un dictionnaire pour stocker les métriques et les prédictions
results_linear = []
Y_pred_linear = pd.DataFrame()

# Créer le dossier pour les modèles si il n'existe pas
output_dir = 'Best_models/L_X/Linear'
os.makedirs(output_dir, exist_ok=True)

# Boucle sur chaque variable cible
for i, col in enumerate(Y_train.columns):
    # Ajuster le modèle sur la colonne actuelle (transformée)
    linear_model.fit(X_train_transformed[:k, :], Y_train_transformed.iloc[:k, i])
    
    # Prédire les valeurs sur le jeu de test (transformé)
    y_pred = linear_model.predict(X_test_transformed[:k, :])
    y_true = Y_test.iloc[:k, i]
    
    # Pas de transformation inverse ici : on utilise directement y_pred (transformation appliquée)
    y_pred_original = y_pred  # Les prédictions sont déjà dans l'échelle transformée

    # Calculer les métriques
    mse = mean_squared_error(y_true, y_pred_original)
    mape = mean_absolute_percentage_error(y_true, y_pred_original)
    r2 = r2_score(y_true, y_pred_original)
    
    # Stocker les résultats
    results_linear.append({
        'Target Column': col,
        'MSE': mse,
        'MAPE': mape,
        'R2': r2
    })
    
    # Stocker les prédictions dans un DataFrame
    Y_pred_linear[col] = y_pred_original

    # Définir le chemin d'enregistrement du modèle pour chaque colonne
    model_path = os.path.join(output_dir, f'{col}_best_model_linear.joblib')  # Sauvegarder dans le bon dossier
    dump(linear_model, model_path)
    print(f"Modèle pour la variable '{col}' enregistré sous {model_path}")

    # Afficher les métriques pour la variable cible
    print(f"Target Column '{col}'")
    print(f"MSE: {mse}, MAPE: {mape}, R²: {r2}")
    print("-" * 40)

# Créer un DataFrame pour résumer les résultats
params_linear = pd.DataFrame(results_linear)

# Afficher le tableau des résultats
print(params_linear)

# Afficher les prédictions (si nécessaire)
# print(Y_pred_linear)








import os
from sklearn.kernel_ridge import KernelRidge
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.model_selection import GridSearchCV
import pandas as pd
from joblib import dump  # Importation de joblib pour sauvegarder les modèles

# Paramètres pour GridSearchCV pour Kernel Ridge Regression
param_grid = {
    'alpha': [0.1, 1, 10],           # Paramètre de régularisation
    'kernel': ['linear', 'rbf'],     # Choix de noyaux
    'gamma': [0.1, 1, 10]            # Paramètre pour le noyau 'rbf'
}

# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible
best_models = {}
best_params_list = []

# Créer le dossier pour les modèles si il n'existe pas
output_dir = 'Best_models/L_X/KRR'
os.makedirs(output_dir, exist_ok=True)

# Boucle sur chaque variable cible (chaque colonne de Y_train)
for i, col in enumerate(Y_train.columns):
    # Initialiser un modèle Kernel Ridge
    krr = KernelRidge()

    # Configurer la recherche de grille
    grid_search = GridSearchCV(
        estimator=krr,
        param_grid=param_grid,
        cv=5,
        scoring='neg_mean_absolute_percentage_error',  # Utiliser MAPE pour optimiser
        n_jobs=-1
    )

    # Ajuster le modèle sur la colonne actuelle de Y_train
    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])

    # Obtenir le meilleur modèle
    best_model = grid_search.best_estimator_
    best_models[col] = best_model

    # Prédire sur les données de test
    y_pred = best_model.predict(X_test_transformed[:k, :])
    y_true = Y_test.iloc[:k, i]

    # Calculer les erreurs
    mse = mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # Stocker les résultats
    best_params_list.append({
        'Target Column': col,
        'alpha': grid_search.best_params_['alpha'],
        'kernel': grid_search.best_params_['kernel'],
        'gamma': grid_search.best_params_['gamma'],
        'MSE': mse,
        'MAPE': mape,
        'R2': r2
    })

    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié
    model_path = os.path.join(output_dir, f'{col}_best_model_KRR.joblib')  # Sauvegarder dans le bon dossier
    dump(best_model, model_path)
    print(f"Modèle pour la variable '{col}' enregistré sous {model_path}")

    # Afficher les résultats pour chaque colonne
    print(f"Target Column '{col}'")
    print("Best Parameters:", grid_search.best_params_)
    print(f"MSE: {mse}, MAPE: {mape}, R²: {r2}")
    print("-" * 40)

# Créer un DataFrame pour résumer les résultats
params_KRR = pd.DataFrame(best_params_list)

# Afficher le tableau des résultats
print(params_KRR)

# Créer un DataFrame pour les prédictions
Y_pred_KRR = pd.DataFrame()
for column, model in best_models.items():
    Y_pred_KRR[column] = model.predict(X_test_transformed[:k, :])

# Afficher les prédictions
#print(Y_pred_KRR)









import os
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.model_selection import GridSearchCV
import pandas as pd
from joblib import dump  # Importation de joblib pour sauvegarder les modèles

# Paramètres pour GridSearchCV pour GradientBoostingRegressor
param_grid = {
    'n_estimators': [10, 100, 300, 500],
    'learning_rate': [0.05, 0.1, 0.5],
    'max_depth': [2, 3]
}

# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible
best_models = {}
best_params_list = []

# DataFrame pour stocker les prédictions pour chaque variable cible
Y_pred_GB = pd.DataFrame()

# Créer le dossier pour les modèles si il n'existe pas
output_dir = 'Best_models/L_X/GB'
os.makedirs(output_dir, exist_ok=True)

# Boucle sur chaque variable de sortie (chaque colonne de Y_train)
for i, col in enumerate(Y_train.columns):
    # Initialiser un modèle de GradientBoostingRegressor
    gbr = GradientBoostingRegressor()
    
    # Configurer la recherche de grille
    grid_search = GridSearchCV(
        estimator=gbr,
        param_grid=param_grid,
        cv=5,
        scoring='neg_mean_absolute_percentage_error',
        n_jobs=-1
    )
    
    # Ajuster le modèle sur la colonne actuelle de Y_train
    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])
    
    # Enregistrer le meilleur modèle pour la variable cible actuelle
    best_model = grid_search.best_estimator_
    best_models[col] = best_model
    
    # Prédictions sur l'ensemble de test
    y_pred = best_model.predict(X_test_transformed)
    y_true = Y_test.iloc[:, i]
    
    # Ajouter les prédictions au DataFrame Y_pred_GB
    Y_pred_GB[col] = y_pred
    
    # Calcul des métriques
    mse = mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # Ajouter les meilleurs paramètres et les scores dans la liste des meilleurs paramètres
    best_params_list.append({
        'Variable': col,
        'n_estimators': grid_search.best_params_['n_estimators'],
        'learning_rate': grid_search.best_params_['learning_rate'],
        'max_depth': grid_search.best_params_['max_depth'],
        'Best Score (MAPE Negatif)': grid_search.best_score_,
        'MSE': mse,
        'MAPE': mape,
        'R2': r2
    })
    
    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié
    model_path = os.path.join(output_dir, f'{col}_best_model_GBR.joblib')  # Sauvegarder dans le bon dossier
    dump(best_model, model_path)
    print(f"Modèle pour la variable '{col}' enregistré sous {model_path}")

    # Afficher les meilleurs hyperparamètres et les scores pour la variable cible actuelle
    print(f"Variable de sortie '{col}'")
    print("Meilleurs paramètres :", grid_search.best_params_)
    print("Meilleur score (MAPE négatif) :", grid_search.best_score_)
    print(f"MSE: {mse}, MAPE: {mape}, R²: {r2}")
    print("-" * 40)

# Créer un DataFrame pour stocker les meilleurs paramètres et les métriques de chaque modèle
params_GB = pd.DataFrame(best_params_list)

# Afficher le DataFrame des meilleurs paramètres
#print(params_GB)








import os
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
import pandas as pd
from joblib import dump  # Importation de joblib pour sauvegarder les modèles

# Paramètres pour GridSearchCV pour XGBoost
param_grid = {
    'n_estimators': [100, 300, 500],  # Nombre d'arbres
    'learning_rate': [0.05, 0.1, 0.3],  # Taux d'apprentissage
    'max_depth': [3, 5, 7],  # Profondeur maximale des arbres
    'subsample': [0.8, 1],  # Fraction des échantillons utilisés pour entraîner chaque arbre
    'colsample_bytree': [0.8, 1]  # Fraction des caractéristiques utilisées pour chaque arbre
}

# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible
best_models = {}
best_params_list = []

# Créer le dossier pour les modèles si il n'existe pas
output_dir = 'Best_models/L_X/XGB'
os.makedirs(output_dir, exist_ok=True)

# Boucle sur chaque variable cible (chaque colonne de Y_train)
for i, col in enumerate(Y_train.columns):
    # Initialiser un modèle XGBoost
    xgbr = XGBRegressor(objective='reg:squarederror', n_jobs=-1)  # Configuré pour minimiser l'erreur quadratique

    # Configurer la recherche de grille
    grid_search = GridSearchCV(
        estimator=xgbr,
        param_grid=param_grid,
        cv=5,
        scoring='neg_mean_absolute_percentage_error',  # Optimisation avec MAPE
        n_jobs=-1
    )

    # Ajuster le modèle sur la colonne actuelle de Y_train
    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])

    # Obtenir le meilleur modèle
    best_model = grid_search.best_estimator_
    best_models[col] = best_model

    # Prédire sur les données de test
    y_pred = best_model.predict(X_test_transformed[:k, :])
    y_true = Y_test.iloc[:k, i]

    # Calculer les erreurs
    mse = mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # Stocker les résultats
    best_params_list.append({
        'Target Column': col,
        'n_estimators': grid_search.best_params_['n_estimators'],
        'learning_rate': grid_search.best_params_['learning_rate'],
        'max_depth': grid_search.best_params_['max_depth'],
        'subsample': grid_search.best_params_['subsample'],
        'colsample_bytree': grid_search.best_params_['colsample_bytree'],
        'MSE': mse,
        'MAPE': mape,
        'R2': r2
    })

    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié
    model_path = os.path.join(output_dir, f'{col}_best_model_XGB.joblib')  # Sauvegarder dans le bon dossier
    dump(best_model, model_path)
    print(f"Modèle pour la variable '{col}' enregistré sous {model_path}")

    # Afficher les résultats pour chaque colonne
    print(f"Target Column '{col}'")
    print("Best Parameters:", grid_search.best_params_)
    print(f"MSE: {mse}, MAPE: {mape}, R²: {r2}")
    print("-" * 40)

# Créer un DataFrame pour résumer les résultats
params_XGB = pd.DataFrame(best_params_list)

# Afficher le tableau des résultats
print(params_XGB)

# Créer un DataFrame pour les prédictions
Y_pred_XGB = pd.DataFrame()
for column, model in best_models.items():
    Y_pred_XGB[column] = model.predict(X_test_transformed[:k, :])

# Afficher les prédictions (si nécessaire)
# print(Y_pred_XGB)








import os
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.model_selection import GridSearchCV
import pandas as pd
from joblib import dump  # Importation de joblib pour sauvegarder les modèles

# Paramètres pour GridSearchCV pour MLPRegressor (ANN)
param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],  # Architectures des couches cachées
    'activation': ['relu', 'tanh'],                               # Fonctions d'activation
    'learning_rate_init': [0.001, 0.01],                          # Taux d'apprentissage initial
    'max_iter': [500, 1000]                                       # Nombre maximal d'itérations
}

# Initialiser un dictionnaire pour stocker les meilleurs modèles pour chaque variable cible
best_models = {}
best_params_list = []

# Créer le dossier pour les modèles si il n'existe pas
output_dir = 'Best_models/L_X/ANN'
os.makedirs(output_dir, exist_ok=True)

# Boucle sur chaque variable cible (chaque colonne de Y_train)
for i, col in enumerate(Y_train.columns):
    # Initialiser un modèle ANN (MLPRegressor)
    mlp = MLPRegressor(random_state=42)

    # Configurer la recherche de grille
    grid_search = GridSearchCV(
        estimator=mlp,
        param_grid=param_grid,
        cv=5,
        scoring='neg_mean_absolute_percentage_error',  # Optimisation avec MAPE
        n_jobs=-1
    )

    # Ajuster le modèle sur la colonne actuelle de Y_train
    grid_search.fit(X_train_transformed[:k, :], Y_train.iloc[:k, i])

    # Obtenir le meilleur modèle
    best_model = grid_search.best_estimator_
    best_models[col] = best_model

    # Prédire sur les données de test
    y_pred = best_model.predict(X_test_transformed[:k, :])
    y_true = Y_test.iloc[:k, i]

    # Calculer les erreurs
    mse = mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # Stocker les résultats
    best_params_list.append({
        'Target Column': col,
        'hidden_layer_sizes': grid_search.best_params_['hidden_layer_sizes'],
        'activation': grid_search.best_params_['activation'],
        'learning_rate_init': grid_search.best_params_['learning_rate_init'],
        'max_iter': grid_search.best_params_['max_iter'],
        'MSE': mse,
        'MAPE': mape,
        'R2': r2
    })

    # Sauvegarder le modèle pour chaque colonne dans le dossier spécifié
    model_path = os.path.join(output_dir, f'{col}_best_model_ANN.joblib')  # Sauvegarder dans le bon dossier
    dump(best_model, model_path)
    print(f"Modèle pour la variable '{col}' enregistré sous {model_path}")

    # Afficher les résultats pour chaque colonne
    print(f"Target Column '{col}'")
    print("Best Parameters:", grid_search.best_params_)
    print(f"MSE: {mse}, MAPE: {mape}, R²: {r2}")
    print("-" * 40)

# Créer un DataFrame pour résumer les résultats
params_ANN = pd.DataFrame(best_params_list)

# Afficher le tableau des résultats
print(params_ANN)

# Créer un DataFrame pour les prédictions
Y_pred_ANN = pd.DataFrame()
for column, model in best_models.items():
    Y_pred_ANN[column] = model.predict(X_test_transformed[:k, :])

# Afficher les prédictions (si nécessaire)
# print(Y_pred_ANN)
